Experiments/
1/ 4conv - 1dense - 1classifier
2/ 3conv (maxPool, BatchNorm) - globalAVGpool - 1dense - 1classifier Acc:0.57
3/ Architecture from OR     Acc: 0.61
4/ Architecture from OR without dropout: 0.65
5/ VGG16  stable Training  Acc: 0.47 
6/ ResNet50 Acc: 0.55
7/ InceptionV3: Acc:0.69
8/ DenseNet12: Acc: 0.70
9/ OR without dropout with GeLu: 0.66
10/ OR w/o dropout w/o regularization: 0.68
11/ Kubanet: 0.716
12/ ORr w/o dropout with regularization two additional layers: 0.66
13/ Kubanet w/o regularization GeLU and SGD:  0.69
14/ Bernet 1.0: 055
15/ Kubanet 2.0 (modified architecture, bigger filters, more features): 0.62
16/ Kubanet with SGD + Nesterov: 0.64
17/ Bernet 2.0 (reduced layers) with label smoothing: 0.56
18/ Kubanet with data augmentation:
19/ Kubanet 3.0 (with additional conv layer): 0.73
20/ Kubanet 3.0 with data augmentation:

3-4-9
OR-Architecture:
conv2d (Conv2D)              
activation (Activation)      
batch_normalization (BatchNo 
conv2d_1 (Conv2D)            
activation_1 (Activation)    
batch_normalization_1 (Batch 
max_pooling2d (MaxPooling2D) 
conv2d_2 (Conv2D)            
activation_2 (Activation)    
batch_normalization_2 (Batch)
conv2d_3 (Conv2D)            
activation_3 (Activation)    
batch_normalization_3 (Batch 
max_pooling2d_1 (MaxPooling2 
conv2d_4 (Conv2D)            
activation_4 (Activation)    
batch_normalization_4 (Batch 
conv2d_5 (Conv2D)            
activation_5 (Activation)    
batch_normalization_5 (Batch 
max_pooling2d_2 (MaxPooling2 
global_average_pooling2d (Gl 
flatten (Flatten)            
dense (Dense)                